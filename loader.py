import pickle
import io
import pprint
import os

os.environ["BITSANDBYTES_NOWELCOME"] = "1"
from llama import ModelArgs, Transformer, Tokenizer, LLaMA, default_quantize

'''
def _is_zipfile(f) -> bool:
    # This is a stricter implementation than zipfile.is_zipfile().
    # zipfile.is_zipfile() is True if the magic number appears anywhere in the
    # binary. Since we expect the files here to be generated by torch.save or
    # torch.jit.save, it's safe to only check the start bytes and avoid
    # collisions and assume the zip has only 1 file.
    # See bugs.python.org/issue28494.

    # Read the first 4 bytes of the file
    read_bytes = []
    start = f.tell()

    byte = f.read(1)
    while byte != b"":
        read_bytes.append(byte)
        if len(read_bytes) == 4:
            break
        byte = f.read(1)
    f.seek(start)

    local_header_magic_number = [b'P', b'K', b'\x03', b'\x04']
    return read_bytes == local_header_magic_number

def _is_torchscript_zip(zip_file):
    return 'constants.pkl' in zip_file.get_all_records()
'''

def sizeof_fmt(num, suffix="B"):
    for unit in ["", "Ki", "Mi", "Gi", "Ti", "Pi", "Ei", "Zi"]:
        if abs(num) < 1024.0:
            return f"{num:3.1f}{unit}{suffix}"
        num /= 1024.0
    return f"{num:.1f}Yi{suffix}"



class HalfStorage:
	def __init__(self, *args, **kwargs) -> None:
		# print('HalfStorage')
		# print("  ", args)
		# print("  ", kwargs)
		pass

class RebuildTensor:
		
	def __init__(self, *args, **kwargs) -> None:
		# print('RebuildTensor')
		# print("  ", args)
		# print("  ", kwargs)

		self.xxargs = args

	def __repr__(self) -> str:
		return str(self.xxargs)		
	



# storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata=None

class UnpicklerWrapper(pickle.Unpickler):  # type: ignore[name-defined]
	# from https://stackoverflow.com/questions/13398462/unpickling-python-objects-with-a-changed-module-path/13405732
	# Lets us override the imports that pickle uses when unpickling an object.
	# This is useful for maintaining BC if we change a module path that tensor instantiation relies on.
	def find_class(self, mod_name, name):

		# print(mod_name, name)

		if name == "_rebuild_tensor_v2":
			return RebuildTensor

		if name == "HalfStorage":
			return HalfStorage

		return super().find_class(mod_name, name)

class DirectoryReader:
    """
    Class to allow PackageImporter to operate on unzipped packages. Methods
    copy the behavior of the internal PyTorchFileReader class (which is used for
    accessing packages in all other cases).

    N.B.: ScriptObjects are not depickleable or accessible via this DirectoryReader
    class due to ScriptObjects requiring an actual PyTorchFileReader instance.
    """

    def __init__(self, directory):
        self.directory = directory

    def get_record(self, name):
        filename = f"{self.directory}/{name}"
        with open(filename, "rb") as f:
            return f.read()

    def get_storage_from_record(self, name, numel):
        filename = f"{self.directory}/{name}"
        nbytes = 2 * numel # @HardcodedElementSize

		# TODO: load

    def has_record(self, path):
        full_path = os.path.join(self.directory, path)
        return os.path.isfile(full_path)

    def get_all_records(
        self,
    ):
        files = []
        for filename in glob(f"{self.directory}/**", recursive=True):
            if not os.path.isdir(filename):
                files.append(filename[len(self.directory) + 1 :])
        return files


def main():

	total_size = 0

	f = open("weights/7B/consolidated.00.pth", 'rb')

	# print(_is_zipfile(f))

	# zip = torch._C.PyTorchFileReader(f)
	zip = DirectoryReader("weights/7B/consolidated")

	data_file = io.BytesIO(zip.get_record("data.pkl"))

	xx = UnpicklerWrapper(data_file, encoding='utf-8')

	def load_tensor(dtype, numel, key, location):
		name = f'data/{key}'
		storage = zip.get_storage_from_record()



	def persistent_load(pid):
		nonlocal total_size

		data = pid[1:]

		typename = pid[0]
		if typename == 'storage':
			storage_type, root_key, location, numel = data
			
			assert storage_type == HalfStorage

			size = numel * 2 # @HardcodedElementSize

			total_size += size

			print(f'size: {sizeof_fmt(size)}')
		return None

	xx.persistent_load = persistent_load

	loaded = xx.load()
	pprint.pprint(loaded)

	print(f'total size: {sizeof_fmt(total_size)}')



if __name__ == "__main__":
	main()